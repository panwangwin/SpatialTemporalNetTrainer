dir:
  base_dir: ./model

train:
  batch_size: 64
  learning_rate: 0.01
  lr_scheduler: True
  lr_decay_rate: 0.1
  lr_milestones: [20,30,40,50]
  epochs: 100
  loss_fn: masked MAELoss
  optimizer: Adam
  weight_decay: 0.01

model:
  model_name: DCRNN
  scheduled_sampling: True
  teaching_tao: 3000
  model_details:
    input_dim: 2
    output_dim: 1
    hidden_dim: 64
    num_layers: 2
    order: 2


data:
  data_dir: ../Datasets/METR-LA/metr-la.h5
  adj_mx_dir: ../Datasets/METR-LA/adj_mx_la.pkl
  train_ratio: 0.8
  test_ratio: 0.1
  val_ratio: 0.1
  seq_len: 12
  horizon: 12


